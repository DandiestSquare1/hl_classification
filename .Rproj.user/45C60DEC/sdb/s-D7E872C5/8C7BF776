{
    "contents" : "rm(list = ls(all = TRUE)); gc() # this removes all the elements from the global environment\n# It's a nice line to have in the start of the script, so it's reproducible.\n# gc() frees memory. Really important with large datasets \n\n# install.packages(c('devtools','data.table', 'caret', 'glmnet'))\n# devtools::install_github('dmlc/xgboost',subdir='R-package')\n\nlibrary(data.table)\nlibrary(caret)\nlibrary(glmnet)\nlibrary(xgboost)\n\n# Read data \nDT <- read.csv('swingData_ES_1.50_v2.csv', sep=',')\nDT <- setDT(DT) # converts the data.frame to data.table\n\n# separate the target from the dataset\ntarget = DT[, 1, with=F]$swingRecordType\nDT[, swingRecordType:=NULL] # remove the column from the training data\n\n# Remove spaces from variable names\nsetnames(DT, names(DT), gsub('[[:space:]]', '', names(DT)))\n# This just removes symbols from the variable names\nsetnames(DT, names(DT), gsub('[[:punct:]]{1,}', '_', names(DT)))\n# see ?regex for more examples\n\n# data.table allows you to loop (really really fast) over each column\n# and is very memory efficient. It changes each column without having an extra copy of the data.\n# This is really relevant when working with large datasets\nfor(j in names(DT))\n  set(DT, j=j, value=ifelse(grepl('TRUE', DT[[j]]), 1, 0))\n\nset.seed(123)\n#shuffle = sample(1:nrow(DT), nrow(DT))\n#DT = DT[shuffle]\n#target = target[shuffle]\n\n### Cross-validation\nX_all = data.matrix(DT)\n\n# selecting number of Rounds\ntarget = ifelse(target == -1, 2, target) # xgboost only accepts class numbers between [0, positive numbers)\ndtest <- xgb.DMatrix(X_all[1:20000, ], label=target[1:20000], missing = NA)\ndtrain <- xgb.DMatrix(X_all[20001:nrow(X_all), ], label=target[20001:length(target)], missing = NA)\n# dtest <- xgb.DMatrix(X_test, missing = NA)\n\n# Set parameters for xgboost model\npar <- list(objective = \"multi:softmax\", # multinomial \n            eval_metric = \"mlogloss\", # loss metric\n            num_class = 3, nthread = 4, \n            eta = 0.2, #learning rate\n            min_child_weight = 50, gamma = .7, # decision tree parameters\n            subsample = 0.6, colsample_bytree = .6, # prevent overfitting - random forest style (column and row sampling)\n            max_depth = 9 # tree maximum depth, controls overfitting. 9 is fairly conservative.\n)\n\n### Run Cross Valication ###\n# to figure out when the model starts overfitting\n# See cvlog.txt. Around 50 trees, the train multinomial log loss function starts \n# separating from the testing set.\ncv.nround = 200\nbst.cv = xgb.cv(param=par, data = dtrain, label = target, \n                nfold = 5, nrounds=cv.nround)\n\n### using a train-test split ###\ngdbt <- xgb.train(param=par, data=dtrain, nrounds=30)\nxgb.dump(gdbt, fname='2xgboost.xgb', with.stats=TRUE)\n\nnames <- colnames(X_all)\nimportance_matrix <- xgb.importance(names, model = gdbt)\nwrite.csv(importance_matrix, file='importance_matrix.txt', row.names = FALSE)\n\n# this saves images of feature importance, I would just look at the raw data. \n# importance_matrix.txt. Higher the Gain, more important the feature.\n# If it's similar to random forest it's mean decrease in gini. \npng('feature_importance.png', width = 400, height = 800)\nxgb.plot.importance(importance_matrix[1:30,])\ndev.off()\n\npng('feature_importance2.png', width = 400, height = 800)\nxgb.plot.importance(importance_matrix[31:60,])\ndev.off()\n\n# Importance_matrix has a table with the gain of each feature\n# This is the \"importance metric\" used by the model\nsave(importance_matrix, file='importance_gdbt.RData')\nsave(gdbt, file='2gdbt.RData') # saves the model object as an RData file\n\n# testing predictions\nyhat = predict(gdbt, dtest, missing = NA)\nyhat = ifelse(yhat == 2, -1, yhat)\ntarget = ifelse(target == 2, -1, target)\n\n# confusion matrix\ncfm = table(target=target[1:20000], yhat=yhat)\n#           yhat\n# target      -1     0     1\n#      -1    749   710     0\n#       0    157 16938   146\n#       1      0   631   669\n\n# Accuracy \nsum(diag(cfm)) / sum(cfm)\n# [1] 0.9178\n\n\n### Regularized logistic regression - LASSO\n# statweb.stanford.edu/~tibs/lasso/lasso.pdf\n# GLMNET R package introduction: \n# http://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html\n\n\n# Try diffent alpha values, tune based on cross validation results.\n# cv.glmnet runs a nfold cross validation, alpha is a parameter that defines\n# what type of regularization mix you are using. \n# If alpha is close to zero, it's close to ridge regression.\n# If alpha is close to 1, it's close to lasso regression\n# LASSO (least absolute shrinkage and selection operator) selects fewer features.\n# It has the advantage that is fast to train On2 and selects the \"best features\".\nfits <- lapply(seq(0, 1, 0.1), function(s){\n  cv.glmnet(X_all[20001:30000, ], y=target[20001:30000],\n            nfolds=3, type.measure = 'class', family=\"multinomial\", alpha=s)\n})\nsave(fits, file='elastic_net.RData')\n\n# Here I select from the models trained previously which had the smallest \n# cross validation missclassification error. (Thats the inverse of accuracy)\ncv_classification_error = lapply(fits, function(fit){\n  fit$cvm[fit$lambda == fit$lambda.1se]\n})\n\n# arrange the results in a data.table\nglmnet_results = data.table(cbind(seq(0, 1, 0.1), do.call(c, cv_classification_error)))\nsetnames(glmnet_results, names(glmnet_results), c('s', 'cv_classification_error'))\n\n# Fit model with all data and best regularization parameter\nbest_s = glmnet_results[which.min(cv_classification_error)]$s # get the best s, from the previous models\n\n# Fit the model with the best parameter with all the training data.\nfit <- cv.glmnet(X_all[20001:nrow(X_all), ], y=target[20001:nrow(X_all)],\n                 nfolds=10, type.measure = 'class', family=\"multinomial\", alpha=best_s)\n\n# Evaluate results in left out data\nprobs = predict(fit, newx=X_all[1:20000, ], type='response', s='lambda.1se')\nprobs = data.table(as.matrix(probs[, ,]))\npred_inx = apply(probs, 1, function(x) which.max(x))\npreds = ifelse(pred_inx == 1, -1,\n               ifelse(pred_inx == 2, 0, 1))\n\ncfm_glmnet = table(target=target[1:20000], yhat=preds)\ncfm_glmnet \n### This is the confusion matrix. \n### shows the real values (target) and predicted values (yhat)\n\n#           yhat\n# target      -1     0     1\n#      -1    717   742     0\n#       0    185 16906   150\n#       1      0   664   636\n\n# accuracy\nsum(diag(cfm_glmnet)) # total of elements in the diagonal of the confusion matrix (correctly classified)\n  / \n  sum(cfm_glmnet) # total of elements\n# 0.91295\n\n# check best features in the regression model\n# this gives the coefficient values for each class, but it returns it in a weird format\n# a sparse matrix. So this is not nice to see results. \ncoef_glm = predict(fit, newx=X_all[1:20000, ], type='coefficients', s='lambda.1se')\n\n# This function just makes taking a look at the coefficients easier. \nget_not_null_coef <- function(coef_glm){\n  # Orders coefficients of each class by the absolute value of each coefficient\n  classes = names(coef_glm)\n  cf = lapply(classes, function(x){\n    vars_class_low = as.matrix(coef_glm[[x]])\n    vars_class_low = vars_class_low[vars_class_low[,1] != 0, ]\n    vars_class_low[order(abs(vars_class_low), decreasing=TRUE)]\n  })\n  names(cf) <- classes\n  cf\n}\n\n# coefs has the value of not-null coefficients\n# ranked by absolute value.\ncoefs = get_not_null_coef(coef_glm)\ncoefs\n\n### Add other model and blend results\n\n# Neural network - fitted using the caret package api.\n# does boostraping by default (25 resamples). Will take some time...\nnnet = train(x=X_all[20001:nrow(X_all), ], y=as.factor(target[20001:nrow(X_all)]),\n      method = 'nnet', metric = 'Accuracy',\n      maximize = TRUE, tuneLength = 10)\n\n\n\n\n",
    "created" : 1441424408816.000,
    "dirty" : false,
    "encoding" : "LATIN1",
    "folds" : "",
    "hash" : "591621028",
    "id" : "8C7BF776",
    "lastKnownWriteTime" : 1441506787,
    "path" : "~/Desktop/dm/free/09_september/hl_classification/2xgboost.R",
    "project_path" : "2xgboost.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}